#!/usr/bin/env python3
"""Count tokens generated by Python LLM for comparison with Rust."""

# Setup paths
DEFAULT_MODEL_DIR = "pretrained_models/Fun-CosyVoice3-0.5B"
DEFAULT_PROMPT_WAV = "./asset/interstellar-tars-01-resemble-denoised.wav"
DEFAULT_PROMPT_TEXT = "Eight months to Mars. Counter-orbital slingshot around 14 months to Saturn. Nothing's changed on that."


def main():
    from cosyvoice.cli.cosyvoice import AutoModel

    print("Loading model...")
    cosyvoice = AutoModel(model_dir=DEFAULT_MODEL_DIR)
    print(f"Model loaded. Sample rate: {cosyvoice.sample_rate} Hz")

    # Test texts (same as example.py)
    texts = [
        "Hello! I am an AI voice assistant powered by Fun-CosyVoice3. How may I help you today?",
        "The quick brown fox jumps over the lazy dog. This sentence contains every letter of the alphabet.",
    ]

    prompt_prefix = "Please speak in English.<|endofprompt|>"
    full_prompt_text = prompt_prefix + DEFAULT_PROMPT_TEXT

    for idx, tts_text in enumerate(texts):
        print(f"\n=== Segment {idx} ===")
        print(f"Text: {tts_text[:50]}...")

        token_count = 0
        for i, output in enumerate(
            cosyvoice.inference_zero_shot(
                tts_text, full_prompt_text, DEFAULT_PROMPT_WAV, stream=False
            )
        ):
            # Count tokens from the speech_token tensor
            if "speech_token" in output:
                token_count = output["speech_token"].numel()
                print(f"  Chunk {i}: {token_count} speech tokens")
            if "tts_speech" in output:
                audio_len = output["tts_speech"].shape[1]
                duration = audio_len / cosyvoice.sample_rate
                print(f"  Chunk {i}: audio {duration:.2f}s ({audio_len} samples)")

        print(f"Total tokens for segment {idx}: {token_count}")


if __name__ == "__main__":
    main()
