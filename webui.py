# Copyright (c) 2024 Alibaba Inc (authors: Xiang Lyu, Liu Yue)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""
Fun-CosyVoice3 Web UI

A Gradio-based web interface for Fun-CosyVoice3-0.5B-2512.
Supports zero-shot voice cloning, cross-lingual synthesis, and instruction-controlled TTS.
"""

import argparse
import os
import random
import sys

import gradio as gr
import numpy as np
import torchaudio

ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append("{}/third_party/Matcha-TTS".format(ROOT_DIR))
from cosyvoice.cli.cosyvoice import AutoModel
from cosyvoice.utils.common import set_all_random_seed
from cosyvoice.utils.file_utils import logging

# =============================================================================
# Inference Modes for Fun-CosyVoice3
# =============================================================================

inference_mode_list = ["3sæé€Ÿå¤åˆ»", "è·¨è¯­ç§å¤åˆ»", "è‡ªç„¶è¯­è¨€æ§åˆ¶"]
instruct_dict = {
    "3sæé€Ÿå¤åˆ»": "1. é€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶ï¼Œæˆ–å½•å…¥promptéŸ³é¢‘ï¼Œæ³¨æ„ä¸è¶…è¿‡30sï¼Œè‹¥åŒæ—¶æä¾›ï¼Œä¼˜å…ˆé€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶\n2. è¾“å…¥promptæ–‡æœ¬\n3. ç‚¹å‡»ç”ŸæˆéŸ³é¢‘æŒ‰é’®",
    "è·¨è¯­ç§å¤åˆ»": "1. é€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶ï¼Œæˆ–å½•å…¥promptéŸ³é¢‘ï¼Œæ³¨æ„ä¸è¶…è¿‡30sï¼Œè‹¥åŒæ—¶æä¾›ï¼Œä¼˜å…ˆé€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶\n2. ç‚¹å‡»ç”ŸæˆéŸ³é¢‘æŒ‰é’®",
    "è‡ªç„¶è¯­è¨€æ§åˆ¶": "1. é€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶\n2. è¾“å…¥instructæ–‡æœ¬ï¼ˆæ§åˆ¶è¯­è¨€ã€æƒ…æ„Ÿã€è¯­é€Ÿç­‰ï¼‰\n3. ç‚¹å‡»ç”ŸæˆéŸ³é¢‘æŒ‰é’®",
}
stream_mode_list = [("å¦", False), ("æ˜¯", True)]
max_val = 0.8


def generate_seed():
    seed = random.randint(1, 100000000)
    return {"__type__": "update", "value": seed}


def change_instruction(mode_checkbox_group):
    return instruct_dict[mode_checkbox_group]


def generate_audio(
    tts_text,
    mode_checkbox_group,
    prompt_text,
    prompt_wav_upload,
    prompt_wav_record,
    instruct_text,
    seed,
    stream,
    speed,
):
    if prompt_wav_upload is not None:
        prompt_wav = prompt_wav_upload
    elif prompt_wav_record is not None:
        prompt_wav = prompt_wav_record
    else:
        prompt_wav = None

    # Validation for instruction mode
    if mode_checkbox_group == "è‡ªç„¶è¯­è¨€æ§åˆ¶":
        if instruct_text == "":
            gr.Warning("æ‚¨æ­£åœ¨ä½¿ç”¨è‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼, è¯·è¾“å…¥instructæ–‡æœ¬")
            yield (cosyvoice.sample_rate, default_data)
            return
        if prompt_wav is None:
            gr.Warning("è¯·æä¾›promptéŸ³é¢‘")
            yield (cosyvoice.sample_rate, default_data)
            return

    # Validation for cross-lingual mode
    if mode_checkbox_group == "è·¨è¯­ç§å¤åˆ»":
        if instruct_text != "":
            gr.Info("æ‚¨æ­£åœ¨ä½¿ç”¨è·¨è¯­ç§å¤åˆ»æ¨¡å¼, instructæ–‡æœ¬ä¼šè¢«å¿½ç•¥")
        if prompt_wav is None:
            gr.Warning("æ‚¨æ­£åœ¨ä½¿ç”¨è·¨è¯­ç§å¤åˆ»æ¨¡å¼, è¯·æä¾›promptéŸ³é¢‘")
            yield (cosyvoice.sample_rate, default_data)
            return
        gr.Info("æ‚¨æ­£åœ¨ä½¿ç”¨è·¨è¯­ç§å¤åˆ»æ¨¡å¼, è¯·ç¡®ä¿åˆæˆæ–‡æœ¬å’Œpromptæ–‡æœ¬ä¸ºä¸åŒè¯­è¨€")

    # Validation for zero-shot mode
    if mode_checkbox_group == "3sæé€Ÿå¤åˆ»":
        if prompt_wav is None:
            gr.Warning("promptéŸ³é¢‘ä¸ºç©ºï¼Œæ‚¨æ˜¯å¦å¿˜è®°è¾“å…¥promptéŸ³é¢‘ï¼Ÿ")
            yield (cosyvoice.sample_rate, default_data)
            return
        if torchaudio.info(prompt_wav).sample_rate < prompt_sr:
            gr.Warning(
                "promptéŸ³é¢‘é‡‡æ ·ç‡{}ä½äº{}".format(
                    torchaudio.info(prompt_wav).sample_rate, prompt_sr
                )
            )
            yield (cosyvoice.sample_rate, default_data)
            return
        if prompt_text == "":
            gr.Warning("promptæ–‡æœ¬ä¸ºç©ºï¼Œæ‚¨æ˜¯å¦å¿˜è®°è¾“å…¥promptæ–‡æœ¬ï¼Ÿ")
            yield (cosyvoice.sample_rate, default_data)
            return
        if instruct_text != "":
            gr.Info("æ‚¨æ­£åœ¨ä½¿ç”¨3sæé€Ÿå¤åˆ»æ¨¡å¼ï¼Œinstructæ–‡æœ¬ä¼šè¢«å¿½ç•¥ï¼")

    # Run inference based on mode
    if mode_checkbox_group == "3sæé€Ÿå¤åˆ»":
        logging.info("get zero_shot inference request")
        set_all_random_seed(seed)
        # Add prompt prefix for better quality
        full_prompt_text = "You are a helpful assistant.<|endofprompt|>" + prompt_text
        for i in cosyvoice.inference_zero_shot(
            tts_text, full_prompt_text, prompt_wav, stream=stream, speed=speed
        ):
            yield (cosyvoice.sample_rate, i["tts_speech"].numpy().flatten())
    elif mode_checkbox_group == "è·¨è¯­ç§å¤åˆ»":
        logging.info("get cross_lingual inference request")
        set_all_random_seed(seed)
        # Add prompt prefix for better quality
        full_tts_text = "You are a helpful assistant.<|endofprompt|>" + tts_text
        for i in cosyvoice.inference_cross_lingual(
            full_tts_text, prompt_wav, stream=stream, speed=speed
        ):
            yield (cosyvoice.sample_rate, i["tts_speech"].numpy().flatten())
    else:  # è‡ªç„¶è¯­è¨€æ§åˆ¶
        logging.info("get instruct inference request")
        set_all_random_seed(seed)
        for i in cosyvoice.inference_instruct2(
            tts_text, instruct_text, prompt_wav, stream=stream, speed=speed
        ):
            yield (cosyvoice.sample_rate, i["tts_speech"].numpy().flatten())


def main():
    with gr.Blocks() as demo:
        gr.Markdown("""
        ### Fun-CosyVoice3 è¯­éŸ³åˆæˆ

        ğŸ¤ **Fun-CosyVoice3-0.5B-2512** - æœ€æ–°ä¸€ä»£è¯­éŸ³åˆæˆæ¨¡å‹

        [GitHub](https://github.com/FunAudioLLM/CosyVoice) |
        [ModelScope](https://www.modelscope.cn/models/FunAudioLLM/Fun-CosyVoice3-0.5B-2512) |
        [HuggingFace](https://huggingface.co/FunAudioLLM/Fun-CosyVoice3-0.5B-2512) |
        [è®ºæ–‡](https://arxiv.org/pdf/2505.17589)
        """)
        gr.Markdown("#### è¯·è¾“å…¥éœ€è¦åˆæˆçš„æ–‡æœ¬ï¼Œé€‰æ‹©æ¨ç†æ¨¡å¼ï¼Œå¹¶æŒ‰ç…§æç¤ºæ­¥éª¤è¿›è¡Œæ“ä½œ")

        tts_text = gr.Textbox(
            label="è¾“å…¥åˆæˆæ–‡æœ¬",
            lines=1,
            value="æˆ‘æ˜¯é€šä¹‰å®éªŒå®¤è¯­éŸ³å›¢é˜Ÿå…¨æ–°æ¨å‡ºçš„ç”Ÿæˆå¼è¯­éŸ³å¤§æ¨¡å‹ï¼Œæä¾›èˆ’é€‚è‡ªç„¶çš„è¯­éŸ³åˆæˆèƒ½åŠ›ã€‚",
        )
        with gr.Row():
            mode_checkbox_group = gr.Radio(
                choices=inference_mode_list,
                label="é€‰æ‹©æ¨ç†æ¨¡å¼",
                value=inference_mode_list[0],
            )
            instruction_text = gr.Text(
                label="æ“ä½œæ­¥éª¤", value=instruct_dict[inference_mode_list[0]], scale=0.5
            )
            stream = gr.Radio(
                choices=stream_mode_list,
                label="æ˜¯å¦æµå¼æ¨ç†",
                value=stream_mode_list[0][1],
            )
            speed = gr.Number(
                value=1,
                label="é€Ÿåº¦è°ƒèŠ‚(ä»…æ”¯æŒéæµå¼æ¨ç†)",
                minimum=0.5,
                maximum=2.0,
                step=0.1,
            )
            with gr.Column(scale=0.25):
                seed_button = gr.Button(value="\U0001f3b2")
                seed = gr.Number(value=0, label="éšæœºæ¨ç†ç§å­")

        with gr.Row():
            prompt_wav_upload = gr.Audio(
                sources="upload",
                type="filepath",
                label="é€‰æ‹©promptéŸ³é¢‘æ–‡ä»¶ï¼Œæ³¨æ„é‡‡æ ·ç‡ä¸ä½äº16khz",
            )
            prompt_wav_record = gr.Audio(
                sources="microphone", type="filepath", label="å½•åˆ¶promptéŸ³é¢‘æ–‡ä»¶"
            )
        prompt_text = gr.Textbox(
            label="è¾“å…¥promptæ–‡æœ¬",
            lines=1,
            placeholder="è¯·è¾“å…¥promptæ–‡æœ¬ï¼Œéœ€ä¸promptéŸ³é¢‘å†…å®¹ä¸€è‡´ï¼Œæš‚æ—¶ä¸æ”¯æŒè‡ªåŠ¨è¯†åˆ«...",
            value="",
        )
        instruct_text = gr.Textbox(
            label="è¾“å…¥instructæ–‡æœ¬ï¼ˆè‡ªç„¶è¯­è¨€æ§åˆ¶æ¨¡å¼ï¼‰",
            lines=1,
            placeholder="ä¾‹å¦‚ï¼šè¯·ç”¨å¹¿ä¸œè¯è¯´è¿™å¥è¯<|endofprompt|>",
            value="",
        )

        generate_button = gr.Button("ç”ŸæˆéŸ³é¢‘")

        audio_output = gr.Audio(label="åˆæˆéŸ³é¢‘", autoplay=True, streaming=True)

        seed_button.click(generate_seed, inputs=[], outputs=seed)
        generate_button.click(
            generate_audio,
            inputs=[
                tts_text,
                mode_checkbox_group,
                prompt_text,
                prompt_wav_upload,
                prompt_wav_record,
                instruct_text,
                seed,
                stream,
                speed,
            ],
            outputs=[audio_output],
        )
        mode_checkbox_group.change(
            fn=change_instruction,
            inputs=[mode_checkbox_group],
            outputs=[instruction_text],
        )
    demo.queue(max_size=4, default_concurrency_limit=2)
    demo.launch(server_name="0.0.0.0", server_port=args.port)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--port", type=int, default=8000)
    parser.add_argument(
        "--model_dir",
        type=str,
        default="pretrained_models/Fun-CosyVoice3-0.5B",
        help="local path or modelscope repo id",
    )
    args = parser.parse_args()
    cosyvoice = AutoModel(model_dir=args.model_dir)

    sft_spk = cosyvoice.list_available_spks()
    if len(sft_spk) == 0:
        sft_spk = [""]
    prompt_sr = 16000
    default_data = np.zeros(cosyvoice.sample_rate)
    main()
