#!/usr/bin/env python3
# Copyright (c) 2024 Alibaba Inc (authors: Xiang Lyu)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""
Fun-CosyVoice3 Example - Voice Cloning Demo

This example demonstrates zero-shot voice cloning using the Fun-CosyVoice3-0.5B-2512 model.
The default reference voice is the interstellar-tars voice clip.
"""

import sys

sys.path.append("third_party/Matcha-TTS")

import torchaudio

from cosyvoice.cli.cosyvoice import AutoModel

# =============================================================================
# Default Voice Cloning Configuration
# =============================================================================

# Reference voice clip for voice cloning
DEFAULT_PROMPT_WAV = "./asset/interstellar-tars-01-resemble-denoised.wav"

# Transcription of the reference voice clip
DEFAULT_PROMPT_TEXT = "Eight months to Mars. Counter-orbital slingshot around 14 months to Saturn. Nothing's changed on that."

# Model directory (will auto-download if not present)
DEFAULT_MODEL_DIR = "pretrained_models/Fun-CosyVoice3-0.5B"


def cosyvoice3_example():
    """CosyVoice3 Usage, check https://funaudiollm.github.io/cosyvoice3/ for more details"""
    cosyvoice = AutoModel(model_dir="pretrained_models/Fun-CosyVoice3-0.5B")
    # zero_shot usage
    for i, j in enumerate(
        cosyvoice.inference_zero_shot(
            "Peter Piper picked a peck of pickled peppers. How many pickled peppers did Peter Piper pick?",
            "You are a helpful assistant.<|endofprompt|>I hope you can do better than me in the future.",
            "./asset/zero_shot_prompt.wav",
            stream=False,
        )
    ):
        torchaudio.save(
            "zero_shot_{}.wav".format(i), j["tts_speech"], cosyvoice.sample_rate
        )

    # fine grained control, for supported control, check cosyvoice/tokenizer/tokenizer.py#L280
    for i, j in enumerate(
        cosyvoice.inference_cross_lingual(
            "You are a helpful assistant.<|endofprompt|>[breath]Because that generation of people[breath]are used to living in the countryside,[breath]neighbors are very active,[breath]um, very familiar.[breath]",
            "./asset/zero_shot_prompt.wav",
            stream=False,
        )
    ):
        torchaudio.save(
            "fine_grained_control_{}.wav".format(i),
            j["tts_speech"],
            cosyvoice.sample_rate,
        )

    # instruct usage, for supported control, check cosyvoice/utils/common.py#L28
    for i, j in enumerate(
        cosyvoice.inference_instruct2(
            "It's rare, usually only during National Day or Mid-Autumn Festival.",
            "You are a helpful assistant. Please use a sad tone.<|endofprompt|>",
            "./asset/zero_shot_prompt.wav",
            stream=False,
        )
    ):
        torchaudio.save(
            "instruct_{}.wav".format(i), j["tts_speech"], cosyvoice.sample_rate
        )
    for i, j in enumerate(
        cosyvoice.inference_instruct2(
            "Received a birthday gift from a friend from afar, that unexpected surprise and deep blessing filled my heart with sweet happiness, smiling like a flower blooming.",
            "You are a helpful assistant. Please speak as fast as possible.<|endofprompt|>",
            "./asset/zero_shot_prompt.wav",
            stream=False,
        )
    ):
        torchaudio.save(
            "instruct_{}.wav".format(i), j["tts_speech"], cosyvoice.sample_rate
        )

    # hotfix usage
    for i, j in enumerate(
        cosyvoice.inference_zero_shot(
            "Executives also praised the report via phone, SMS, WeChat, etc.",
            "You are a helpful assistant.<|endofprompt|>I hope you can do better than me in the future.",
            "./asset/zero_shot_prompt.wav",
            stream=False,
        )
    ):
        torchaudio.save(
            "hotfix_{}.wav".format(i), j["tts_speech"], cosyvoice.sample_rate
        )


def voice_cloning_example():
    """
    Zero-shot voice cloning example.

    Uses the default reference voice to synthesize new text.
    """
    print("=" * 60)
    print("Fun-CosyVoice3 Voice Cloning Example")
    print("=" * 60)

    # Initialize model
    print(f"\nğŸ“¦ Loading model from: {DEFAULT_MODEL_DIR}")
    cosyvoice = AutoModel(model_dir=DEFAULT_MODEL_DIR)
    print(f"âœ… Model loaded. Sample rate: {cosyvoice.sample_rate} Hz")

    # Example texts to synthesize
    texts = [
        "Hello! I am an AI voice assistant powered by Fun-CosyVoice3. How may I help you today?",
        "The quick brown fox jumps over the lazy dog. This sentence contains every letter of the alphabet.",
    ]

    # Prompt prefix for better quality (recommended for CosyVoice3)
    prompt_prefix = "You are a helpful assistant.<|endofprompt|>"
    full_prompt_text = prompt_prefix + DEFAULT_PROMPT_TEXT

    print(f"\nğŸ¤ Reference voice: {DEFAULT_PROMPT_WAV}")
    print(f'ğŸ“ Reference transcription: "{DEFAULT_PROMPT_TEXT}"')

    for idx, tts_text in enumerate(texts):
        print(f'\nğŸ”Š Synthesizing [{idx + 1}/{len(texts)}]: "{tts_text[:50]}..."')

        for i, output in enumerate(
            cosyvoice.inference_zero_shot(
                tts_text, full_prompt_text, DEFAULT_PROMPT_WAV, stream=False
            )
        ):
            output_path = f"output_voice_clone_{idx}_{i}.wav"
            torchaudio.save(output_path, output["tts_speech"], cosyvoice.sample_rate)
            print(f"   ğŸ’¾ Saved: {output_path}")

    print("\nâœ¨ Voice cloning complete!")


def cosyvoice3_example():
    """CosyVoice3 Usage, check https://funaudiollm.github.io/cosyvoice3/ for more details"""
    cosyvoice = AutoModel(model_dir="pretrained_models/Fun-CosyVoice3-0.5B")
    # zero_shot usage
    for i, j in enumerate(
        cosyvoice.inference_zero_shot(
            "å…«ç™¾æ ‡å…µå¥”åŒ—å¡ï¼ŒåŒ—å¡ç‚®å…µå¹¶æ’è·‘ï¼Œç‚®å…µæ€•æŠŠæ ‡å…µç¢°ï¼Œæ ‡å…µæ€•ç¢°ç‚®å…µç‚®ã€‚",
            "You are a helpful assistant.<|endofprompt|>å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚",
            "./asset/zero_shot_prompt.wav",
            stream=False,
        )
    ):
        torchaudio.save(
            "zero_shot_{}.wav".format(i), j["tts_speech"], cosyvoice.sample_rate
        )

    # fine grained control, for supported control, check cosyvoice/tokenizer/tokenizer.py#L280
    for i, j in enumerate(
        cosyvoice.inference_cross_lingual(
            "You are a helpful assistant.<|endofprompt|>[breath]å› ä¸ºä»–ä»¬é‚£ä¸€è¾ˆäºº[breath]åœ¨ä¹¡é‡Œé¢ä½çš„è¦ä¹ æƒ¯ä¸€ç‚¹ï¼Œ[breath]é‚»å±…éƒ½å¾ˆæ´»ç»œï¼Œ[breath]å—¯ï¼Œéƒ½å¾ˆç†Ÿæ‚‰ã€‚[breath]",
            "./asset/zero_shot_prompt.wav",
            stream=False,
        )
    ):
        torchaudio.save(
            "fine_grained_control_{}.wav".format(i),
            j["tts_speech"],
            cosyvoice.sample_rate,
        )

    # instruct usage, for supported control, check cosyvoice/utils/common.py#L28
    for i, j in enumerate(
        cosyvoice.inference_instruct2(
            "å¥½å°‘å’¯ï¼Œä¸€èˆ¬ç³»æ”¾å—°å•²å›½åº†å•Šï¼Œä¸­ç§‹å—°å•²å¯èƒ½ä¼šå’¯ã€‚",
            "You are a helpful assistant. è¯·ç”¨å¹¿ä¸œè¯è¡¨è¾¾ã€‚<|endofprompt|>",
            "./asset/zero_shot_prompt.wav",
            stream=False,
        )
    ):
        torchaudio.save(
            "instruct_{}.wav".format(i), j["tts_speech"], cosyvoice.sample_rate
        )
    for i, j in enumerate(
        cosyvoice.inference_instruct2(
            "æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚",
            "You are a helpful assistant. è¯·ç”¨å°½å¯èƒ½å¿«åœ°è¯­é€Ÿè¯´ä¸€å¥è¯ã€‚<|endofprompt|>",
            "./asset/zero_shot_prompt.wav",
            stream=False,
        )
    ):
        torchaudio.save(
            "instruct_{}.wav".format(i), j["tts_speech"], cosyvoice.sample_rate
        )

    # hotfix usage
    for i, j in enumerate(
        cosyvoice.inference_zero_shot(
            "é«˜ç®¡ä¹Ÿé€šè¿‡ç”µè¯ã€çŸ­ä¿¡ã€å¾®ä¿¡ç­‰æ–¹å¼å¯¹æŠ¥é“[j][Ç]äºˆå¥½è¯„ã€‚",
            "You are a helpful assistant.<|endofprompt|>å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚",
            "./asset/zero_shot_prompt.wav",
            stream=False,
        )
    ):
        torchaudio.save(
            "hotfix_{}.wav".format(i), j["tts_speech"], cosyvoice.sample_rate
        )


def instruct_example():
    """
    Instruction-controlled synthesis example.

    Uses natural language instructions to control speech style.
    """
    print("\n" + "=" * 60)
    print("Fun-CosyVoice3 Instruction Example")
    print("=" * 60)

    cosyvoice = AutoModel(model_dir=DEFAULT_MODEL_DIR)

    # Text with style instruction
    tts_text = "Today is a beautiful day. The sun is shining and birds are singing."
    instruct_text = (
        "You are a helpful assistant. Please speak slowly and calmly.<|endofprompt|>"
    )

    print(f"\nğŸ¤ Reference voice: {DEFAULT_PROMPT_WAV}")
    print(f'ğŸ“ Instruction: "{instruct_text}"')
    print(f'ğŸ“ Text: "{tts_text}"')

    for i, output in enumerate(
        cosyvoice.inference_instruct2(
            tts_text, instruct_text, DEFAULT_PROMPT_WAV, stream=False
        )
    ):
        output_path = f"output_instruct_{i}.wav"
        torchaudio.save(output_path, output["tts_speech"], cosyvoice.sample_rate)
        print(f"   ğŸ’¾ Saved: {output_path}")

    print("\nâœ¨ Instruction-controlled synthesis complete!")


def main():
    """Run the voice cloning example by default."""
    # voice_cloning_example()
    cosyvoice3_example()

    # Uncomment to run additional examples:
    # instruct_example()


if __name__ == "__main__":
    main()
