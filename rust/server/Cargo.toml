[package]
name = "cosyvoice-server"
version.workspace = true
edition.workspace = true

[[bin]]
name = "cosyvoice-server"
path = "src/main.rs"

[lib]
name = "cosyvoice_rust_backend"
crate-type = ["cdylib", "rlib"]

[dependencies]
# Workspace dependencies
shared = { path = "../shared" }
serde.workspace = true
serde_json.workspace = true
tokio.workspace = true
axum.workspace = true
tower-http.workspace = true
pyo3.workspace = true
numpy.workspace = true
<<<<<<< HEAD
candle-core = { version = "0.9.2-alpha.2" }
candle-nn = { version = "0.9.2-alpha.2" }
candle-transformers = { version = "0.9.2-alpha.2" }
candle-kernels = { version = "0.9.2-alpha.2", optional = true }
# candle-flash-attn = { version = "0.9.2-alpha.2" }
=======
candle-core = { version = "0.8.2" }
candle-nn = { version = "0.8.2" }
candle-transformers = { version = "0.8.2" }
candle-kernels = { version = "0.8.2", optional = true }
# candle-flash-attn = { version = "0.8.2" }
>>>>>>> origin/main
tracing.workspace = true
tracing-subscriber.workspace = true
metrics.workspace = true
metrics-exporter-prometheus.workspace = true
tikv-jemallocator.workspace = true
thiserror.workspace = true
hound.workspace = true
anyhow.workspace = true
dotenvy.workspace = true
bytes = "1.9"
<<<<<<< HEAD
ndarray = "0.15"
ort = { version = "2.0.0-rc.10", default-features = false, features = ["ndarray", "download-binaries", "cuda", "tensorrt"] }
=======
>>>>>>> origin/main
rand = "0.8"

[features]
default = []
cuda = [
    "candle-core/cuda",
    "candle-nn/cuda",
    "candle-transformers/cuda",
    "candle-kernels",
]
